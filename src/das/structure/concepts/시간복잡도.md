### 시간복잡도

> 자료구조 + 알고리즘 > 컴퓨터 위 코드로 동작 > 하지만 HW/SW 환경이 제각각!
> 그러나 다양한 크기의 입력을 일관되게 처리/측정할 수 없음

따라서 가상 컴퓨터(Virtual Machine) + 가상 언어(Pseudo Language) + 가상 코드(Pseudo Code)를 정의하여, 환경에 구애받지 않고 일관성 있게 알고리즘 성능을 측정함.

#### 1. 가상 머신: RAM (Random Access Machine) 모델

- 초기 튜링 머신(Turing Machine)을 넘어 폰 노이만이 제시한 모델.
- 구성: CPU + Memory + 프로그램(기본 연산의 집합)
- 핵심: 가장 간단한 기본 연산을 반복하여 CPU와 일을 하는 것이 알고리즘, 이때 이 연산을 1 단위시간(Unit Time)으로 측정하여 성능 평가하는 개념
- 기본 연산
    - 배정 (Assignment): `A = B` (B를 읽고 A에 쓴다. 가장 기본)
    - 산술 (Arithmetic): `+`, `-`, `*`, `/` (나머지, 올림, 버림 등도 1 단위 시간 취급)
    - 비교 (Comparison): `>`, `>=`, `<`, `<=`, `!=` (두 수의 비교는 결국 뺄셈 로직 기반. 산술과 동일 취급)
    - 논리 (Logic): `AND`, `OR`, `NOT`
    - 비트 (Bitwise): `bit-AND`, `OR`, `NOT`

#### 2. 가상 언어 (Pseudo Language)
- RAM 모델의 기본 연산을 표현하고 시뮬레이션하기 위한 언어.
- 실제 프로그래밍 언어보다 자유로운 문법
- 구성:
  - 기본 연산 표현 (배정, 산술, 비교 등)
  - 제어 흐름: `if`, `if-else` (분기)
  - 반복문: `for`, `while`
  - 함수: 정의, 호출, 리턴

#### 3. 가상 코드 (Pseudo Code) 예시 및 분석

가상 컴퓨터(RAM) 위에서 코드를 돌릴 때, 단순히 입력 크기(N)만으로는 연산 횟수를 확정할 수 없는 문제가 발생하여 통일된 측정 기준 필요하다.

- 동일한 입력 크기 n이라도 데이터의 구성에 따라 연산 횟수가 달라질 수 있고 모든 입력 케이스에 대한 평균을 구하는 것은 현실적으로 불가능하다. 
- 때문에, 알고리즘 성능 분석에서는 가장 불리한 입력이 들어왔을 때를 가정한 최악 시간 복잡도(Worst-Case Time Complexity)를 표준 기준으로 삼는다.
- WTC는 "어떤 입력이 들어와도 이 시간 이상은 걸리지 않는다"는 상한선(Upper Bound)을 보장한다.

그럼 WTC는 어떻게 구할 수 있는가? 다음 예시 참고

##### 예시1: 최대값 찾기

```algorithm
algorithm ArrayMax(A, n):
    input: N개의 정수 갖는 배열 A
    output: A의 수 중에서 최대값 리턴
    
    currentMax = A[0]        // (1) 초기화: 배정 1회
    for i = 1 to n-1 do      // (총 n-1회 반복)
        if currentMax < A[i]: // (2) 비교: 1회
            currentMax = A[i] // (3) 배정: 1회 (조건 만족 시)
    return currentMax
```

- 상황: 배열의 원소를 하나씩 순회하며 최댓값을 갱신.
- 최악의 입력(Worst Case): 오름차순으로 정렬된 배열 (예: [1, 2, 3, 4, 5]) → 매번 갱신 발생.

**[성능 측정]**
- 초기화: currentMax = A[0] → 1회
- 반복문 내부 (n - 1회 반복):
  - if 비교 (1회) + currentMax 배정 (1회) = 2회
- 총 연산 횟수 T(n):

$$ 1 + (n-1) \times 2 = 2n - 1 $$

##### 예시2: 단일 반복문 누적 합

```algorithm
algorithm sum1(A, n):
    sum = 0                  // (1) 초기화: 배정 1회
    for i = 0 to n-1 do      // (총 n회 반복)
        if A[i] % 2 == 0:     // (2) 조건: 나머지(1) + 비교(1) = 2회
            sum += A[i]       // (3) 합산: 덧셈(1) + 배정(1) = 2회
    return sum
```

- 상황: 배열의 원소 중 짝수인 것만 골라 합산.
- 최악의 입력(Worst Case): 모든 원소가 짝수인 경우 (예: `[2, 4, 6, 8]`) → 매번 `if`문 통과 및 합산 발생.

**[성능 측정]**
- 초기화: `sum = 0` → 1회
- 반복문 내부 ($n$회 반복):
    - `if` 조건 (`%`, `==`) = 2회
    - `sum` 누적 (`+`, `=`) = 2회
    - 반복 1회당 총 4회
- 총 연산 횟수 $T(n)$:

$$1 + (n \times 4) = 4n + 1 $$

##### 예시3: 이중 반복문 곱의 합

```algorithm
algorithm sum2(A, n):
    sum = 0                  // (1) 초기화: 배정 1회
    for i = 0 to n-1 do      // (외부 루프)
        for j = i to n-1 do  // (내부 루프: i값에 따라 횟수 감소)
            sum += A[i] * A[j] // (2) 연산: 곱셈(1) + 덧셈(1) + 배정(1) = 3회
    return sum
```

- **상황:** 모든 쌍(Pair)의 곱을 누적 합산. (중첩 루프 구조)
- **입력:** 배열 `A`의 값과 상관없이 루프 횟수는 고정됨 (`j`는 `i`부터 시작).

[성능 측정]
- 초기화: 1회
- 반복 횟수 분석 (가우스의 덧셈):
    - $i=0$일 때 $j$는 $n$회, $i=1$일 때 $j$는 $n-1$회 ... $i=n-1$일 때 $1$회. (수학적 증명은 각설하고, 즉)
    - 전체 반복 횟수 = $n + (n-1) + \dots + 1 = \frac{n(n+1)}{2}$
- 내부 연산: 곱셈, 덧셈, 배정 = 3회
- 총 연산 횟수 $T(n)$:

$$ 1 + \left( \frac{n(n+1)}{2} \times 3 \right) = \frac{3}{2}n^2 + \frac{3}{2}n + 1 $$

---

**내가 이해한 핵심:** N이 무한대 수준이면 4n+1이나 2n-1이나 거기서 거기다. N에 비례해서 늘어나되, 성능 시간의 증가율은 최고차항이 결정한다. 즉, 최고차항(가장 영향력 큰 놈)만 남겨도 무방하다. 
 
- 예시1 -> 최고차항 n -> O(n) -> 선형 시간
- 예시2 -> 최고차항 n -> O(n) -> 선형 시간
- 예시3 -> 최고차항 n^2 -> O(n^2) -> 이차(제곱) 시간

이렇게 함수값을 결정하는 최고차항만으로 간단히 표기하는 것이 'Big-O 표기법'.

### Big-O 종류와 성능 순서

기본 연산을 대략 세어 최고차항만 남기는 것이 Big-O의 핵심이다. 입력 크기 n이 무한히 커질 때, 연산 횟수가 증가하는 패턴(기울기)에 따라 다음과 같이 분류된다.

#### 1. 상수 시간 (Constant Time): O(1)

입력 N의 크기와 상관없이 항상 일정한 시간(연산 횟수)이 걸리는 경우.

```python
def increment_one(n):
    return n + 1  # 연산 1회 (산술)
```

- 분석: N이 1이든 100억이든 덧셈 연산은 딱 1번 수행된다.
- 표기: $T(n) = C$ (상수) $\rightarrow O(1)$
- 특징: 가장 빠르다. 배열의 인덱스 접근(`A[i]`), 스택의 `push`/`pop` 등이 해당.

#### 2. 로그 시간 (Logarithmic Time): $O(\log n)$

입력 N이 커질 때, 연산 횟수가 아주 완만하게 늘어나는 경우. 주로 문제를 절반씩 쪼개면서 해결할 때 나타난다.

```python
def number_of_bits(n):
    count = 0
    while n > 0:
        n = n // 2  # 입력 n을 계속 반으로 나눔
        count += 1 
    return count
```

- 분석 (Why $\log n$?):
    - 반복문이 돌 때마다 n은 절반으로 줄어든다. ($n \rightarrow n/2 \rightarrow n/4 \dots \rightarrow 1$)
    - 즉, "$2$를 몇 번($k$) 곱해야 $n$이 되는가?"를 묻는 것과 역으로 같다. ($2^k \approx n$)
    - 이를 수학적으로 표현하면 $k = \log_2 n$이다.
- 표기: $T(n) = \log_2 n$ $\rightarrow O(\log n)$
- 특징: $N$이 2배 늘어나도 연산은 고작 1회 늘어난다. 대단히 빠르다. (이분 탐색 등)

#### 3. 선형 시간 (Linear Time): $O(n)$

입력 N만큼 정직하게 반복하는 경우.

```python
def print_all(n):
    for i in range(n):  # n회 반복
        print(i)
```

- 분석: N이 10배 되면 실행 시간도 정확히 10배 늘어난다.
- 표기: $T(n) = n$ $\rightarrow O(n)$
- 특징: 가장 일반적인 `for`문 1개 구조.

#### 4. 선형 로그 시간 (Linear-Logarithmic Time): $O(n \log n)$

$O(n)$과 $O(\log n)$이 결합된 형태.

- 상황: 데이터를 절반씩 쪼개는($\log n$) 작업을 n번 수행하는 경우.
- 표기: $O(n \log n)$
- 특징: 효율적인 정렬 알고리즘(Merge Sort, Quick Sort 등)의 표준 성능.

#### 5. 이차 시간 (Quadratic Time): $O(n^2)$

입력 N의 제곱만큼 시간이 걸리는 경우.

```python
def nested_loop(n):
    for i in range(n):      # n회
        for j in range(n):  # n회
            print(i, j)
```

- 분석: 중첩 반복문(Double Loop). N이 10배 되면 시간은 100배($10^2$) 늘어난다.
- 표기: $T(n) = n \times n = n^2$ $\rightarrow O(n^2)$
- 특징: 데이터가 조금만 많아져도 느려진다. (버블 정렬, 선택 정렬 등)

#### 6. 삼차 시간 (Cubic Time): $O(n^3)$

- 상황: 삼중 중첩 반복문 (Triple Loop).
- 특징: N이 100만 넘어가도 100만 회 연산. 보통 알고리즘 문제에서 N이 클 때 $O(n^3)$으로 풀면 시간 초과 확정.

#### 7. 지수 시간 (Exponential Time): $O(2^n)$

입력 N이 하나 늘어날 때마다 시간이 2배로 폭발하는 경우.

```python
def fibonacci(n):
    if n <= 1: return n
    return fibonacci(n-1) + fibonacci(n-2) # 재귀 호출이 2갈래로 뻗어나감
```

- 분석: 한 번 단계가 지날 때마다 연산량이 2배씩 증식한다.
- 특징: 최악의 성능. N이 30만 넘어도 수십억 회 연산이 필요해 멈춰버림.

---

### 최종 정리: 성능 비교 (빠름 $\rightarrow$ 느림)

$$ O(1) < O(\log n) < O(n) < O(n \log n) < O(n^2) < O(n^3) < O(2^n) $$

- 핵심: 오른쪽으로 갈수록 그래프의 기울기가 급격해진다.
- 전략: 문제를 풀 때 입력 크기(N)를 보고, 허용 가능한 Big-O를 역산하여 알고리즘을 선택해야 한다. (예: $N=100,000$이면 $O(n^2)$은 시간 초과이므로 $O(n \log n)$ 이하로 짜야 함)